# Hyperparameter Exploration in Convolutional Neural Network

Zheren Zheng

The aim of this work is to evaluate the role of hyperparameters network size, learning rate, optimization methods and batch size during neural network training and investigate how they improve the training process. This work uses the dataset \textbf{CIFAR-10} which contains 60,000 pictures (32 $\times$ 32 pixels using 3 RGB channels) for the classification task. The architecture of neural newtork employed in this work is VGG. The analysis focuses on how the hyperparameters effect computation time, the number of epochs to finish training and the accuracy achieved by the training set and validation set.
